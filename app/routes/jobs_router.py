# ðŸ§­ jobs_router.py â€” "The Queue Commander" (CN PERFECTO VERSION)
# ============================================================

import logging
from uuid import UUID
from fastapi import (
    APIRouter,
    Depends,
    HTTPException,
    status,
)
from typing import List
from sqlalchemy.ext.asyncio import AsyncSession # ðŸŽ¯ Use AsyncSession everywhere!

# ðŸ§± --- Core System Imports ---
from app.db.database import get_db_session # ðŸŽ¯ Using the ASYNC session generator
from app.db.models.user_model import User
from app.db.models.job_model import Job
from app.schemas.job_schema import JobSubmission, JobRead
from app.services import job_service
from app.services.user_service import get_current_user
from app.tasks.job_tasks import process_data 
# ðŸŽ›ï¸ --- Initialize Logger & Router ---
logger = logging.getLogger(__name__)
jobs_router = APIRouter()


# ============================================================
# ðŸŽ¯ CREATE NEW JOB (POST /jobs)
# ============================================================
@jobs_router.post(
    "/",
    response_model=JobRead,
    status_code=status.HTTP_202_ACCEPTED,
    summary="ðŸ“¬ Submit a new asynchronous job",
    description="""
    1ï¸âƒ£ Creates a new job record in Postgres with status **PENDING** 2ï¸âƒ£ Dispatches the task to the Celery queue
    3ï¸âƒ£ Returns the created job immediately (HTTP 202)
    """,
)
async def create_job( # ðŸŽ¯ ROUTER MUST BE ASYNC
    job_data: JobSubmission,
    db: AsyncSession = Depends(get_db_session), # ðŸŽ¯ ASYNC SESSION
    current_user: User = Depends(get_current_user),
) -> Job:
    """
    ðŸ§© Steps:
    1. Insert the new Job record into Postgres (status=PENDING)
    2. Push an async task to Celery for background processing
    3. Return the Job to the user immediately
    """

    user_id = current_user.id
    logger.info(f"ðŸ“¦ User {user_id} submitting new job...")

    # Step 1ï¸âƒ£ â€” Record job in DB
    try:
        # ðŸŽ¯ MUST AWAIT THE SERVICE CALL
        db_job = await job_service.create_job(db=db, job_data=job_data, user=current_user)
        logger.info(
            f"ðŸª£ Job {db_job.job_id} recorded in DB with status {db_job.status}"
        )
    except Exception as e:
        logger.error(f"ðŸ’¥ Failed to record job in DB for user {user_id}: {e}")
        # The service layer should ideally handle its own transaction rollback
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to record job in database. Please retry later.",
        )

    # Step 2ï¸âƒ£ & 3ï¸âƒ£ â€” Send Celery Task and Update ID
    try:
        task = process_data.delay(str(db_job.job_id))

        # ðŸŽ¯ CN FIX: Use a clean, awaited update function call
        await job_service.update_job_id(
            db=db,
            db_job=db_job, # Pass the ORM object
            celery_task_id=task.id, # Pass the ID directly
        )

        logger.info(
            f"ðŸš€ Celery task dispatched for Job {db_job.job_id}. Task ID: {task.id}"
        )

    except Exception as e:
        logger.error(f"âš ï¸ Failed to dispatch Celery task for job {db_job.job_id}: {e}")
        # Only raise 503 if the Celery system is essential and down
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Asynchronous processing unavailable. Job left in PENDING.",
        )

    logger.info(f"âœ… Job {db_job.job_id} accepted for background processing.")
    return db_job


# ============================================================
# ðŸ” GET JOB STATUS (GET /jobs/{job_id})
# ============================================================
@jobs_router.get(
    "/{job_id}",
    response_model=JobRead,
    summary="ðŸ“Š Retrieve Job Status",
    description="Fetches the jobâ€™s current status and result (if available).",
)
async def get_job_status( # ðŸŽ¯ MUST BE ASYNC
    job_id: UUID,
    db: AsyncSession = Depends(get_db_session), # ðŸŽ¯ ASYNC SESSION
    current_user: User = Depends(get_current_user), # User object, not dict
) -> Job:
    """
    ðŸ§© Steps:
    1. Retrieve a specific Job by ID
    2. Ensure the requesting user owns that job
    3. Return the job record and its status/result
    """

    user_id = current_user.id
    logger.info(f"ðŸ” Checking job {job_id} for user {user_id}")

    # ðŸŽ¯ MUST AWAIT THE SERVICE CALL
    db_job = await job_service.get_job_by_id(db=db, job_id=job_id, user_id=user_id)

    if not db_job:
        logger.warning(f"ðŸš« Job {job_id} not found or access denied for {user_id}")
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Job not found or access denied.",
        )

    logger.info(f"ðŸ“ˆ Job {job_id} retrieved successfully (status={db_job.status})")
    return db_job


# ============================================================
# ðŸ§¹ BONUS: GET ALL JOBS FOR USER (GET /jobs)
# ============================================================
@jobs_router.get(
    "/",
    response_model=List[JobRead],
    summary="ðŸ“œ List All Jobs for Current User",
)
async def list_user_jobs( # ðŸŽ¯ MUST BE ASYNC
    db: AsyncSession = Depends(get_db_session), # ðŸŽ¯ ASYNC SESSION
    current_user: User = Depends(get_current_user), # User object, not dict
) -> List[Job]:
    """Returns all jobs belonging to the logged-in user."""
    user_id = current_user.id
    logger.info(f"ðŸ§¾ Listing all jobs for user {user_id}")

    # ðŸŽ¯ MUST AWAIT THE SERVICE CALL
    jobs = await job_service.get_jobs_for_user(db=db, user_id=user_id)
    return jobs