# app/config.yaml

# ğŸ§  Default model used for text generation
default_model: llama3.2

# ğŸ§° Available models for text generation
available_text_models:
  - llama3.2
  - deepseek.chat
  - gpt4.openai

# ğŸ§ª Execution modes
modes:
  simple: "Local CPU, minimal outputs"
  enriched: "Full artifact generation"
  premium: "Paid model routing for high fidelity"

# âš™ï¸ System settings
max_tokens: 2048
temperature: 0.7

# ğŸ“ Storage paths
minio_bucket: helixnet
default_template: sceneprompt.j2